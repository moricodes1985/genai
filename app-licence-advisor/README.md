# ğŸ“š Open-Source License Copilot (RAG Demo)

An interactive chatbot that answers **questions about open-source software licenses** using **Retrieval-Augmented Generation (RAG)**.  
Built with [LlamaIndex](https://www.llamaindex.ai/), an LLM backend, and [Gradio](https://gradio.app/) for the UI.

âš ï¸ Disclaimer: This tool is **for educational purposes only** and **not legal advice**.

---

## âœ¨ Features
- **Multi-source document ingestion**  
  - Plaintext license files (e.g., MIT, Apache-2.0)  
  - Markdown guides (e.g., choosealicense.com excerpts)  
  - HTML pages (e.g., OSI license descriptions)  
  - Structured CSV/JSON (e.g., SPDX license metadata)  

- **Retrieval-augmented QA**  
  - Embedding-based retrieval with [HuggingFace models](https://huggingface.co/)  
  - Citations to source documents in every answer  

- **Interactive Chatbot**  
  - Gradio chat UI with conversation history  
  - Optional file upload (e.g., `package.json`) for contextual queries  
  - Toggle between *strict quoting* vs *helpful explanation* modes  

- **Extensible Architecture**  
  - Easy to add more licenses, documents, or retrievers  
  - Modular pipeline for future improvements (rerankers, graph-RAG, evaluations)  

---

## ğŸ—‚ï¸ Project Structure

```
/app-licence-advisor
â”œâ”€ app/
â”‚ â”œâ”€ main.py # FastApi backend
â”‚ â”œâ”€ rag.py # Query engine setup
â”‚ â”œâ”€ ui.py # Gradio frontend that calls main.py API
â”‚ â”œâ”€ guards.py # Disclaimer / response guards
â”œâ”€ ingest/
â”‚ â”œâ”€ build_index.py # Ingestion + index building
â”‚ â””â”€ loaders.py # Custom document loaders
â”œâ”€ data/
â”‚ â”œâ”€ poc/ # Sample docs (MIT, Apache-2.0, etc.)
â”‚ â””â”€ processed/ # Cleaned/normalized artifacts
â”œâ”€ storage/ # Persisted vector index
â”œâ”€ requirements.txt
â”œâ”€ README.md
â””â”€ LICENSE
```

---

## ğŸš€ Getting Started

Create a virtual environment
```
python3 -m venv .venv
source .venv/bin/activate

```
### Run with Docker Compose

Build the images and start the services:

```bash
# Build without cache
docker compose build --no-cache 

# Start the stack
docker compose up

```
### Gradio UI 
```
http://localhost:7860/
```
## Example Queries
```
â€œWhat permissions does the MIT license grant?â€

â€œWhat obligations do I have under Apache-2.0?â€

â€œIs GPL-3.0 compatible with MIT?â€

â€œShow me SPDX metadata for GPL-3.0.â€
```

## ğŸ› ï¸ Tech Stack
```
Python 3.10+

LlamaIndex â€“ ingestion, indices, RAG pipeline

OpenAI GPT-4o-mini (default LLM)

HuggingFace embeddings â€“ semantic retrieval

Gradio â€“ interactive chatbot UI
```

## ğŸ“ˆ Roadmap
```
 Add more licenses & OSI docs

 Hybrid retrieval (BM25 + embeddings)

 Reranker for better answer quality

 Evaluation harness (faithfulness, relevancy)

 Knowledge-graph index for license compatibility questions

 Dockerfile for one-click deployment
 ```

 âš ï¸ Disclaimer

This project is an educational demo of Retrieval-Augmented Generation.
It is not legal advice. For real licensing questions, consult a qualified attorney.